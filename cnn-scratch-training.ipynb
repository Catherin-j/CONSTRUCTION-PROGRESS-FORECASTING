{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83603d0a-7461-4fb4-a989-5b4e625eef97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch==2.2.2 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (2.2.2)\n",
      "Requirement already satisfied: torchvision==0.17.2 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (0.17.2)\n",
      "Requirement already satisfied: torchaudio==2.2.2 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (2.2.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from torch==2.2.2) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from torch==2.2.2) (4.12.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from torch==2.2.2) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from torch==2.2.2) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from torch==2.2.2) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from torch==2.2.2) (2024.5.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from torchvision==0.17.2) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from torchvision==0.17.2) (10.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from jinja2->torch==2.2.2) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from sympy->torch==2.2.2) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch==2.2.2 torchvision==0.17.2 torchaudio==2.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d152e9d5-13fc-4ea3-bcc5-e870f9a66964",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import glob\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a45365cf-aa21-454e-a857-86ae3cd86312",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for device\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fa02464-1b25-4830-9383-fd616a43d28a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56b13a56-b5cc-4fbc-8f4b-652e53ddefe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforms\n",
    "transformer=transforms.Compose([\n",
    "    transforms.Resize((150,150)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),  #0-255 to 0-1, numpy to tensors\n",
    "    transforms.Normalize([0.5,0.5,0.5], # 0-1 to [-1,1] , formula (x-mean)/std\n",
    "                        [0.5,0.5,0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "986d4136-4e9c-41a9-be8c-652a7fcd7db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a1e280d-8134-4357-9870-28c0c120949e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataloader\n",
    "\n",
    "#Path for training and testing directory\n",
    "train_path='C:\\\\Users\\\\LENOVO\\\\OneDrive\\\\Desktop\\\\computer vision\\\\training'\n",
    "test_path='C:\\\\Users\\\\LENOVO\\\\OneDrive\\\\Desktop\\\\computer vision\\\\testing'\n",
    "\n",
    "train_loader=DataLoader(\n",
    "    torchvision.datasets.ImageFolder(train_path,transform=transformer),\n",
    "    batch_size=32, shuffle=True\n",
    ")\n",
    "test_loader=DataLoader(\n",
    "    torchvision.datasets.ImageFolder(test_path,transform=transformer),\n",
    "    batch_size=32, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd23dbc1-dd50-46ee-913a-fe2575e8ba4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#categories\n",
    "root=pathlib.Path(train_path)\n",
    "classes=sorted([j.name.split('/')[-1] for j in root.iterdir()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eec75c16-ac09-4b07-827e-1a7d8e11e6a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['100%', '30%', '60%', '90%']\n"
     ]
    }
   ],
   "source": [
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a13a9b02-d7b7-49e4-b15c-65108857b825",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN Network\n",
    "\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self,num_classes=4):\n",
    "        super(ConvNet,self).__init__()\n",
    "        \n",
    "        #Output size after convolution filter\n",
    "        #((w-f+2P)/s) +1\n",
    "        \n",
    "        #Input shape= (32,3,150,150)\n",
    "        \n",
    "        self.conv1=nn.Conv2d(in_channels=3,out_channels=12,kernel_size=3,stride=1,padding=1)\n",
    "        #Shape= (20,12,150,150)\n",
    "        self.bn1=nn.BatchNorm2d(num_features=12)\n",
    "        #Shape= (20,12,150,150)\n",
    "        self.relu1=nn.ReLU()\n",
    "        #Shape= (20,12,150,150)\n",
    "        \n",
    "        self.pool=nn.MaxPool2d(kernel_size=2)\n",
    "        #Reduce the image size be factor 2\n",
    "        #Shape= (20,12,75,75)\n",
    "        \n",
    "        \n",
    "        self.conv2=nn.Conv2d(in_channels=12,out_channels=20,kernel_size=3,stride=1,padding=1)\n",
    "        #Shape= (20,20,75,75)\n",
    "        self.relu2=nn.ReLU()\n",
    "        #Shape= (20,20,75,75)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.conv3=nn.Conv2d(in_channels=20,out_channels=32,kernel_size=3,stride=1,padding=1)\n",
    "        #Shape= (20,32,75,75)\n",
    "        self.bn3=nn.BatchNorm2d(num_features=32)\n",
    "        #Shape= (20,32,75,75)\n",
    "        self.relu3=nn.ReLU()\n",
    "        #Shape= (20,32,75,75)\n",
    "        \n",
    "        \n",
    "        self.fc=nn.Linear(in_features=75 * 75 * 32,out_features=num_classes)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #Feed forwad function\n",
    "        \n",
    "    def forward(self,input):\n",
    "        output=self.conv1(input)\n",
    "        output=self.bn1(output)\n",
    "        output=self.relu1(output)\n",
    "            \n",
    "        output=self.pool(output)\n",
    "            \n",
    "        output=self.conv2(output)\n",
    "        output=self.relu2(output)\n",
    "            \n",
    "        output=self.conv3(output)\n",
    "        output=self.bn3(output)\n",
    "        output=self.relu3(output)\n",
    "            \n",
    "            \n",
    "            #Above output will be in matrix form, with shape (20,32,75,75)\n",
    "            \n",
    "        output=output.view(-1,32*75*75)\n",
    "            \n",
    "            \n",
    "        output=self.fc(output)\n",
    "            \n",
    "        return output\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86e2c4c8-f8cd-4dac-a623-66756ea068ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ConvNet(num_classes=4).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06e3d7be-6f29-4608-be30-d43ae1fc0553",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optmizer and loss function\n",
    "optimizer=Adam(model.parameters(),lr=0.001,weight_decay=0.0001)\n",
    "loss_function=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcfc51bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac4dcedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the size of training and testing images\n",
    "train_count=len(glob.glob(train_path+'/**/*.jpg'))\n",
    "test_count=len(glob.glob(test_path+'/**/*.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2413f2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "443 443\n"
     ]
    }
   ],
   "source": [
    "print(train_count,test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1779ea81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Roaming\\Python\\Python312\\site-packages\\PIL\\Image.py:1000: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Loss: tensor(19.2168) Train Accuracy: 0.5079006772009029 Test Accuracy: 0.22799097065462753\n",
      "Epoch: 1 Train Loss: tensor(4.7786) Train Accuracy: 0.7381489841986456 Test Accuracy: 0.35665914221218964\n",
      "Epoch: 2 Train Loss: tensor(2.3151) Train Accuracy: 0.835214446952596 Test Accuracy: 0.8939051918735892\n",
      "Epoch: 3 Train Loss: tensor(1.5420) Train Accuracy: 0.9345372460496614 Test Accuracy: 0.909706546275395\n",
      "Epoch: 4 Train Loss: tensor(0.8673) Train Accuracy: 0.9729119638826185 Test Accuracy: 0.9796839729119639\n",
      "Epoch: 5 Train Loss: tensor(0.7702) Train Accuracy: 0.9706546275395034 Test Accuracy: 0.945823927765237\n",
      "Epoch: 6 Train Loss: tensor(0.7211) Train Accuracy: 0.9751693002257337 Test Accuracy: 0.9887133182844243\n",
      "Epoch: 7 Train Loss: tensor(1.8121) Train Accuracy: 0.9435665914221218 Test Accuracy: 0.9142212189616253\n",
      "Epoch: 8 Train Loss: tensor(0.8836) Train Accuracy: 0.9932279909706546 Test Accuracy: 1.036117381489842\n",
      "Epoch: 9 Train Loss: tensor(0.5768) Train Accuracy: 1.0158013544018059 Test Accuracy: 0.963882618510158\n"
     ]
    }
   ],
   "source": [
    "#Model training and saving best model\n",
    "\n",
    "best_accuracy=0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    #Evaluation and training on training dataset\n",
    "    model.train()\n",
    "    train_accuracy=0.0\n",
    "    train_loss=0.0\n",
    "    \n",
    "    for i, (images,labels) in enumerate(train_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            images=Variable(images.cuda())\n",
    "            labels=Variable(labels.cuda())\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs=model(images)\n",
    "        loss=loss_function(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        train_loss+= loss.cpu().data*images.size(0)\n",
    "        _,prediction=torch.max(outputs.data,1)\n",
    "        \n",
    "        train_accuracy+=int(torch.sum(prediction==labels.data))\n",
    "        \n",
    "    train_accuracy=train_accuracy/train_count\n",
    "    train_loss=train_loss/train_count\n",
    "    \n",
    "    \n",
    "    # Evaluation on testing dataset\n",
    "    model.eval()\n",
    "    \n",
    "    test_accuracy=0.0\n",
    "    for i, (images,labels) in enumerate(test_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            images=Variable(images.cuda())\n",
    "            labels=Variable(labels.cuda())\n",
    "            \n",
    "        outputs=model(images)\n",
    "        _,prediction=torch.max(outputs.data,1)\n",
    "        test_accuracy+=int(torch.sum(prediction==labels.data))\n",
    "    \n",
    "    test_accuracy=test_accuracy/test_count\n",
    "    \n",
    "    \n",
    "    print('Epoch: '+str(epoch)+' Train Loss: '+str(train_loss)+' Train Accuracy: '+str(train_accuracy)+' Test Accuracy: '+str(test_accuracy))\n",
    "    \n",
    "    #Save the best model\n",
    "    if test_accuracy>best_accuracy:\n",
    "        torch.save(model.state_dict(),'best_checkpoint.model')\n",
    "        best_accuracy=test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a7285a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
